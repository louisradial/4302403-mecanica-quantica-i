\section*{Exercício 5}

\begin{definition}{Matrizes de Pauli}{pauli}
    As \emph{matrizes de Pauli} são definidas por
    \begin{equation*}
        \sigma_1 = \begin{pmatrix}
            0&1\\1&0
        \end{pmatrix},\quad\sigma_2 = \begin{pmatrix}
            0&-i\\i&0
        \end{pmatrix},\quad\text{e}\quad\sigma_3 = \begin{pmatrix}
            1&0\\0&-1
        \end{pmatrix}.
    \end{equation*}
\end{definition}

\begin{proposition}{Relações algébricas das matrizes de Pauli}{pauli}
    As matrizes de Pauli satisfazem as relações
    \begin{equation*}
        [\sigma_a,\sigma_b] = 2i \sum_{c = 1}^3 \epsilon_{abc}\sigma_c,\quad
        \{\sigma_a, \sigma_b\} = 2\delta_{ab} \mathds{1},\quad\text{e}\quad
        \sigma_a \sigma_b = \delta_{ab} \mathds{1} + i \sum_{c = 1}^3 \epsilon_{abc}\sigma_c,
    \end{equation*}
    onde \(\epsilon_{abc}\) é o símbolo de Levi-Civita e \(\mathds{1}\) é a matriz identidade.
\end{proposition}
\begin{proof}
    Calculando os nove possíveis produtos, temos
    \begin{equation*}
        \sigma_1 \sigma_1 = \sigma_2 \sigma_2 = \sigma_3 \sigma_3 = \begin{pmatrix}
            1&0\\0&1
        \end{pmatrix} = \mathds{1},
    \end{equation*}
    \begin{align*}
        \sigma_1 \sigma_2 &= \begin{pmatrix}
            i&0\\0&-i
        \end{pmatrix} = i \sigma_3,&
        \sigma_2 \sigma_1 &= \begin{pmatrix}
            -i&0\\0&i
        \end{pmatrix} = -i \sigma_3,&
            [\sigma_1, \sigma_2] &= 2i \sigma_3,\\
        \sigma_1 \sigma_3 &= \begin{pmatrix}
            0&-1\\1&0
        \end{pmatrix} = -i \sigma_2,&
        \sigma_3 \sigma_1 &= \begin{pmatrix}
            0&1\\-1&0
        \end{pmatrix} = i \sigma_2,&
            [\sigma_1, \sigma_3] &= -2i \sigma_2,\\
        \sigma_2 \sigma_3 &= \begin{pmatrix}
            0&i\\i&0
        \end{pmatrix} = i \sigma_1,&
        \sigma_2 \sigma_1 &= \begin{pmatrix}
            0&-i\\-i&0
        \end{pmatrix} = -i \sigma_1,&
            [\sigma_2, \sigma_3] &= 2i \sigma_1,\\
    \end{align*}
    portanto segue que
    \begin{equation*}
        [\sigma_a, \sigma_b] = 2i \sum_{c=1}^3 \epsilon_{abc}\sigma_c\quad\text{e}\quad\{\sigma_a, \sigma_b\} = 2 \delta_{ab} \mathds{1}.
    \end{equation*}
    Somando estas duas expressões, obtemos
    \begin{equation*}
        2\sigma_a \sigma_b = 2 \delta_{ab} \mathds{1} + 2i\sum_{c = 1}^3 \epsilon_{abc}\sigma_c,
    \end{equation*}
    como desejado.
\end{proof}

\begin{proposition}{Exponencial de um vetor de Pauli}{exponencial_pauli}
    Seja \(\vec\eta = \eta_1 \vetor{e}_x + \eta_2\vetor{e}_y + \eta_3 \vetor{e}_z\) um vetor unitário de \(\mathbb{R}^3\). Seja o \emph{vetor de Pauli} a combinação linear
    \begin{equation*}
        \vec\eta \cdot \vec\sigma = \eta_1 \sigma_1 + \eta_2 \sigma_2 + \eta_3 \sigma_3,
    \end{equation*}
    então
    \begin{equation*}
        \exp(i \theta \vec\eta \cdot \vec\sigma) = (\cos\theta)\mathds{1} + (i\sin\theta)(\vec\eta \cdot\vec\sigma),
    \end{equation*}
    para todo \(\theta\in \mathbb{C}.\)
\end{proposition}
\begin{proof}
    Pela \cref{prop:pauli}, temos
    \begin{align*}
        (\vec \eta \cdot \vec \sigma)^2 &= \sum_{k=1}^3 \eta_k \sigma_k \sum_{\ell = 1}^3 \eta_\ell \sigma_\ell\\
                                        &= \sum_{k=1}^3\sum_{\ell=1}^3 \eta_k \eta_\ell \left(\delta_{k\ell}\mathds{1} + i \sum_{m = 1}^3 \epsilon_{k\ell m}\sigma_m\right)\\
                                        &= \sum_{k=1}^3 (\eta_k)^2 \mathds{1} + i\sum_{k=1}^3\sum_{\ell=1}^3 \sum_{m = 1}^3 \eta_k \eta_\ell\epsilon_{k\ell m}\sigma_m\\
                                        &= \mathds{1} + \frac12 \sum_{k=1}^3\sum_{\ell=1}^3 \eta_k \eta_\ell [\sigma_k, \sigma_\ell]\\
                                        &= \mathds{1} + \frac12 \sum_{k=1}^3 [\eta_k \sigma_k, \vec \eta \cdot \vec \sigma]\\
                                        &= \mathds{1} + \frac12 [\vec \eta\cdot \vec \sigma, \vec \eta\cdot \vec \sigma]\\
                                        &= \mathds{1},
    \end{align*}
    onde usamos a bilinearidade e anticomutatividade do comutador.

    Mostremos por indução em \(m \in \mathbb{N}\) que
    \begin{equation*}
        (i\theta\vec \eta \cdot \vec \sigma)^{2m} = (-1)^m\theta^{2m}\mathds{1}\quad\text{e}\quad(i\theta\vec \eta \cdot \vec \sigma)^{2m+1} = (-1)^{m}i\theta^{2m+1}\vec \eta \cdot \vec \sigma,
    \end{equation*}
    para todo \(\theta \in \mathbb{C}\). Essas igualdades seguem trivialmente para \(m = 0\) e para \(m = 1\) temos
    \begin{equation*}
        (i\theta \vec \eta\cdot \vec \sigma)^2 = - \theta^2 \mathds{1}\quad\text{e}\quad(i\theta\vec\eta\cdot\vec\sigma)^3 = -i\theta^3 \vec \eta \cdot \vec \sigma,
    \end{equation*}
    como proposto. Suponhamos que as igualdades sejam satisfeitas para algum \(k \in \mathbb{N}\), então
    \begin{align*}
        (i\theta\vec \eta \cdot \vec \sigma)^{2k+2} &= (i\theta\vec \eta \cdot \vec \sigma)(i\theta\vec \eta \cdot \vec \sigma)^{2k+1}\\
                                                    &= (i\theta\vec \eta \cdot \vec \sigma)\left[(-1)^ki\theta^{2k+1}\vec \eta\cdot \vec \sigma\right]\\
                                                    &= (-1)^{k+1}\theta^{2k+2} \mathds{1}
    \end{align*}
    e
    \begin{align*}
        (i\theta\vec \eta \cdot \vec \sigma)^{2k+3} &= (i\theta\vec \eta \cdot \vec \sigma)(i\theta\vec \eta \cdot \vec \sigma)^{2k+2}\\
                                                    &= (i\theta\vec \eta \cdot \vec \sigma)\left[(-1)^{k+1}\theta^{2k+2} \mathds{1}\right]\\
                                                    &= (-1)^{k+1}i\theta^{2k+3}\vec \eta \cdot \vec \sigma,
    \end{align*}
    isto é, as igualdades são satisfeitas por \(k + 1\). Pelo princípio da indução finita, são válidas para todo \(m \in \mathbb{N}\).

    Assim, para todo \(\theta \in \mathbb{C}\), temos
    \begin{align*}
        \exp(i\theta \vec \eta \cdot \vec \sigma) &= \sum_{\ell = 0}^{\infty} \frac{(i \theta \vec \eta \cdot \vec \sigma)^n}{n!}\\
                                                  &= \left[\sum_{m = 0}^{\infty} \frac{(-1)^{m}\theta^{2m}}{(2m)!}\right] \mathds{1} + \left[\sum_{m=0}^\infty\frac{(-1)^m \theta^{2m+1}}{(2m+1)!}\right] i \vec \eta \cdot \vec \sigma\\
                                                  &= (\cos\theta)\mathds{1} + (i\sin\theta)(\vec \eta \cdot \vec \sigma),
    \end{align*}
    como desejado.
\end{proof}

\begin{exercício}{Exponencial de matriz}{exercício5}
    A exponencial de uma matriz \(M\) é definida pela série
    \begin{equation*}
        \exp(M) = \mathds{1} + \sum_{k = 1}^{\infty} \frac{1}{k!} M^{k},
    \end{equation*}
    onde \(\mathds{1}\) é a matriz identidade.
    \begin{enumerate}[label=(\alph*)]
        \item Determine \(\exp(i\theta \sigma_2), \exp(\theta \sigma_3)\) e \(\exp(\theta \sigma_2)\) com \(\theta \in \mathbb{R}\).
        \item Mostre que se \(M\) é diagonalizável, então \(\det(\exp(M)) = \exp(\Tr(M))\).
        \item Mostre que se as matrizes \(M\) e \(N\) comutam, então \(\exp(M+N) = \exp(M)\exp(N)\).
        \item Mostre que se \(H\) é hermitiana, então \(\exp(iH)\) é unitária.
        \item Mostre que qualquer matriz \(T\) pode ser escrita como uma soma de uma matriz simétrica e uma matriz antissimétrica, como a soma de uma matriz real e uma matriz imaginária, e como uma matriz hermitiana e uma matriz anti-hermitiana.
    \end{enumerate}
\end{exercício}
\begin{proof}[Resolução do item (a)]
    Pela \cref{prop:exponencial_pauli}, temos \(\exp(i\theta \sigma_2) = (\cos\theta)\mathds{1} + (i \sin \theta) \sigma_2\), isto é
    \begin{equation*}
        \exp \begin{pmatrix}
            0 && \theta\\
            -\theta && 0
        \end{pmatrix} = \begin{pmatrix}
            \cos\theta && \sin\theta\\
            -\sin\theta && \cos\theta
        \end{pmatrix}
    \end{equation*}
    para todo \(\theta \in \mathbb{R}\). Ainda por este resultado, segue que
    \begin{align*}
        \exp(\theta \sigma_n) &= (\cos(-i\theta))\mathds{1} + (i \sin(-i\theta))\sigma_n\\
                              &= (\cosh\theta)\mathds{1} + (\sinh\theta)\sigma_n,
    \end{align*}
    portanto
    \begin{align*}
        \exp \begin{pmatrix}
            \theta && 0\\
            0 && - \theta
            \end{pmatrix} &=
        \begin{pmatrix}
            e^\theta && 0\\
            0 && e^{-\theta}
        \end{pmatrix}&
        \exp \begin{pmatrix}
            0 && -i\theta\\
            i \theta && 0
            \end{pmatrix} &= \begin{pmatrix}
            \cosh\theta && -i\sinh\theta\\
            i\sinh\theta && \cosh\theta
        \end{pmatrix}
    \end{align*}
    para todo \(\theta \in \mathbb{R}\).
\end{proof}
\begin{proof}[Resolução do item (b)]
    Se \(M\) é diagonalizável, então é semelhante à matriz diagonal \(D\) cujos elementos são os autovalores de \(M\). Isto é, existe \(P\) invertível tal que \(P^{-1}MP = D\).

    Mostraremos que \(\exp(D) = P^{-1}\exp(M)P\). Para todo \(n \in \mathbb{N}\), segue por indução que \((P^{-1}MP)^n = P^{-1} M^nP\). A igualdade é trivialmente satisfeita para \(n = 1\). Supondo que a identidade vale para \(k \in \mathbb{N}\), temos
    \begin{equation*}
        (P^{-1}MP)^{k+1} = (P^{-1}MP)(P^{-1}MP)^k = (P^{-1}MP)(P^{-1}M^kP) = P^{-1} M^{k+1} P,
    \end{equation*}
    isto é, o resultado segue para \(k + 1\). O princípio de indução finita garante que a igualdade de fato vale para todo \(n \in \mathbb{N}\). Deste modo, temos
    \begin{align*}
        \exp(D) &= \mathds{1} + \sum_{n = 1}^\infty \frac{1}{n!} (P^{-1}MP)^n\\
                &= P^{-1}\mathds{1} P + \sum_{n = 1}^\infty \frac1{n!}P^{-1} M^n P\\
                &= P^{-1} \left(\mathds{1} + \sum_{n=1}^\infty \frac{1}{n!} M^n\right)P\\
                &= P^{-1} \exp(M) P,
    \end{align*}
    como desejado.

    Sejam \ffamily{\lambda_m}{m=1}{N} os autovalores de \(M\), então
    \begin{align*}
        \exp(D) &= \mathds{1} + \sum_{n=1}^\infty \frac{1}{n!} \begin{pmatrix}
            \lambda_1 && 0 && \dots && 0\\
            0 && \lambda_2 && \dots && 0\\
            \vdots && \vdots && \ddots && \vdots \\
            0 && 0 && \dots && \lambda_N
        \end{pmatrix}^n\\
                &= \mathds{1} + \sum_{n=1}^\infty \begin{pmatrix}
                    \frac{\lambda_1^n}{n!} && 0 && \dots && 0\\
                    0 && \frac{\lambda_2^n}{n!} && \dots && 0\\
            \vdots && \vdots && \ddots && \vdots \\
            0 && 0 && \dots && \frac{\lambda_N^n}{n!}
        \end{pmatrix}\\
                &=  \begin{pmatrix}
                   \sum_{n=0}^\infty \frac{\lambda_1^n}{n!} && 0 && \dots && 0\\
                    0 && \sum_{n=0}^\infty\frac{\lambda_2^n}{n!} && \dots && 0\\
            \vdots && \vdots && \ddots && \vdots \\
            0 && 0 && \dots && \sum_{n=0}^\infty\frac{\lambda_N^n}{n!}
        \end{pmatrix}\\
                &= \begin{pmatrix}
                    e^{\lambda_1} && 0 && \dots && 0\\
                    0 && e^{\lambda_2} && \dots && 0\\
            \vdots && \vdots && \ddots && \vdots \\
            0 && 0 && \dots && e^{\lambda_N}
                \end{pmatrix}.
    \end{align*}
    Desse modo, temos
    \begin{equation*}
        \det(\exp(M)) = \det(P\exp(D)P^{-1}) = \det(\exp(D)) = \prod_{n = 1}^{N} e^{\lambda_n} = \exp{\left(\sum_{n=1}^N \lambda_n\right)} = \exp(\Tr(M)),
    \end{equation*}
    como queríamos demonstrar.
\end{proof}
\begin{proof}[Resolução do item (c)]
    Se as matrizes \(M\) e \(N\) comutam, mostraremos por indução em \(n\) que
    \begin{equation*}
        (M + N)^n = \sum_{m = 0}^{n} \binom{n}{m} M^m N^{n-m}
    \end{equation*}
    para todo \(n \in \mathbb{N}\). Para \(n = 1\), a soma do lado direito claramente resulta em \(M + N\). Supondo que a igualdade segue para algum \(k \in \mathbb{N}\), temos pela regra de Pascal que
    \begin{align*}
        (M+N)^{k+1} &= (M+N)\sum_{m=0}^k\binom{k}{m} M^m N^{k-m}\\
                    &= \sum_{m = 1}^{k+1} \binom{k}{m} M^m N^{k+1-m} + \sum_{m=0}^{k} \binom{k}{m-1} M^m N^{k+1-m}\\
                    &= M^{k+1} + N^{k+1} + \sum_{m=1}^{k} \left[\binom{k}{m} + \binom{k}{m-1}\right] M^m N^{k+1-m}\\
                    &= \binom{k+1}{k+1} M^{k+1} + \binom{k+1}{0}N^{k+1} + \sum_{m=1}^{k} \binom{k+1}{m} M^m N^{k+1-m}\\
                    &= \sum_{m=1}^{k+1} \binom{k+1}{m} M^m N^{k+1 - m},
    \end{align*}
    isto é, a identidade é válida para \(k+1\). Pelo princípio de indução finita, o resultado segue para todo número natural.

    Assim, a exponencial da soma das matrizes é dada por
    \begin{align*}
        \exp(M+N) &= \sum_{n = 0}^\infty \frac{1}{n!} \sum_{m=0}^n \binom{n}{m} M^m N^{n - m}\\
                  &= \sum_{n=0}^\infty \sum_{m\leq n} \left(\frac{1}{m!}M^m\right) \left(\frac{1}{(n-m)!} N^{n-m}\right)\\
                  &= \sum_{m=0}^\infty \sum_{n \geq m} \left(\frac{1}{m!} M^m\right) \left(\frac{1}{(n-m)!}N^{n-m}\right)\\
                  &= \sum_{m=0}^\infty \frac{1}{m!} M^m \sum_{\ell = 0}^\infty \frac{1}{\ell!} N^\ell\\
                  &= \exp(M)\exp(N),
    \end{align*}
    como desejado.
\end{proof}
\begin{proof}[Resolução do item (d)]

\end{proof}
\begin{proof}[Resolução do item (e)]

\end{proof}
